{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 9: Correlation, Regression, and Least Squares\n",
    "\n",
    "Please complete this notebook by filling in the cells provided. When youâ€™re done, follow the instructions in [this short explainer video](https://www.youtube.com/watch?v=gMt_Rq43y_4&ab_channel=FahadKamran) to submit your homework.\n",
    "\n",
    "If you cannot submit online, come to office hours for assistance. The office hours\n",
    "schedule appears on [data8.org/fa16/weekly.html](http://data8.org/fa16/weekly.html).\n",
    "\n",
    "This assignment is due Thursday, November 10 at 7PM. You will receive an early submission bonus point if you turn it in by Wednesday, November 3 at 7PM. Directly sharing answers is not okay, but discussing problems with course staff or with other students is encouraged.\n",
    "\n",
    "**Important note:** Only Parts 1 and 2 of this assignment will be graded.  Parts 3 and 4 of this assignment will not be graded and are intended to give you extra practice.\n",
    "\n",
    "Reading:\n",
    "- Textbook chapter [12](https://www.inferentialthinking.com/chapters/12/why-the-mean-matters.html) (for review)\n",
    "- Textbook chapter [13](https://www.inferentialthinking.com/chapters/13/prediction.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to prepare the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up the notebook, but please don't change it.\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "from matplotlib import patches\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from client.api.assignment import load_assignment\n",
    "tests = load_assignment('hw09.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "## Evaluating NBA Game Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A brief introduction to sports betting\n",
    "In a basketball game, each team scores some number of points.  Conventionally, the team playing at its own arena is called the \"home team,\" and the other team is called the \"away team.\"  The winner, of course, is the team with the most points.  So we could summarize what happened in a game by the following number:\n",
    "\n",
    "$$\\text{outcome} = \\text{points scored by the away team} - \\text{points scored by the home team}$$\n",
    "\n",
    "If this number is positive, the away team won.  If it's negative, the home team won.  For brevity, we'll use the shorthand **\"outcome\"** for **the away team's score minus the home team's score**.\n",
    "\n",
    "Casinos in Las Vegas offer bets on the outcomes of NBA games.  One kind of bet works like this:\n",
    "\n",
    "1. The casino decides on a \"spread.\"\n",
    "2. You can bet \\$11 that the outcome will be above the spread, or \\$11 that the outcome will be below the spread.\n",
    "3. After the game, you end up with \\$21 if you guessed correctly, and \\$0 if you guessed incorrectly.\n",
    "\n",
    "The analysts at the casino try to choose the spread so that (according to their analysis of the teams) there is a 50% chance that the outcome will be below that amount, and a 50% chance that the outcome will be above that amount.\n",
    "\n",
    "**[tl;dr](https://en.wikipedia.org/wiki/Wikipedia:Too_long;_didn%27t_read): The spread is the casino's best guess at the outcome (the away team's score minus the home team's score).**\n",
    "\n",
    "The table `spreads` contains spreads from the betting website [Covers](http://www.covers.com) from every game in the 2014 NBA season, plus actual game outcomes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spreads = Table.read_table(\"spreads.csv\")\n",
    "spreads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 1\n",
    "Make a scatter plot of the outcomes and spreads, with the spreads on the horizontal axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spreads.scatter(\"Spread\", \"Outcome\") #SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "You might notice that spreads and outcomes are (almost) never 0.  It's because a game of basketball never ends in a tie; one team has to win.\n",
    "\n",
    "Let's investigate how well the casinos are predicting game outcomes.\n",
    "\n",
    "One question we can ask is: Is the casino's prediction correct on average? In other words, for every value of the spread, is the average outcome of games assigned that spread equal to the spread? If not, the casino would apparently be making a systematic error in its predictions.\n",
    "\n",
    "#### Question 2\n",
    "Among games with a spread around 5 (concretely: in the range $[3.5, 6.5]$), what was the average outcome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spreads_around_5 = spreads.where(\"Spread\", are.between_or_equal_to(3.5, 6.5)) #SOLUTION\n",
    "spread_5_outcome_average = np.mean(spreads_around_5.column(\"Outcome\")) #SOLUTION\n",
    "print(\"Average outcome:\", spread_5_outcome_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of doing that for each possible spread, we can use linear regression to predict an outcome for any spread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 3\n",
    "If the average outcome for games with each spread is roughly equal to that spread, what would you expect the slope and intercept of the linear regression line to be?  Or is it impossible to say?  If it's impossible, use the cell below to write a comment explaining why.  Otherwise, write the expected slope and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected_slope = 1 #SOLUTION\n",
    "expected_intercept = 0 #SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the regression line and find out if that's the case.  This takes a few steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 4\n",
    "Define a function called `standard_units`.  It should take an array of numbers as its argument and return an array of those numbers in standard units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standard_units(nums):\n",
    "    \"\"\"Converts an array of numbers to standard units.\"\"\"\n",
    "    return (nums - np.mean(nums)) / np.std(nums) #SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 5\n",
    "Compute the correlation between outcomes and spreads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spread_r = np.mean(standard_units(spreads.column(\"Outcome\")) * standard_units(spreads.column(\"Spread\"))) #SOLUTION\n",
    "spread_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 6\n",
    "Compute the slope and intercept of the least-squares linear regression line that predicts outcomes from spreads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spread_slope = spread_r * np.std(spreads.column(\"Outcome\")) / np.std(spreads.column(\"Spread\")) #SOLUTION\n",
    "spread_intercept = np.mean(spreads.column(\"Outcome\")) - spread_slope*np.mean(spreads.column(\"Spread\")) #SOLUTION\n",
    "print(\"predicted outcome = {:f}*spread + {:f}\".format(spread_slope, spread_intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 7\n",
    "For each game in `spreads`, compute the predicted outcome using your regression line.  Add these to `spreads` as a column called `\"Predicted outcome\"`, naming the resulting table `with_predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with_predictions = spreads.with_column(\"Predicted outcome\", spread_slope*spreads.column(\"Spread\") + spread_intercept) #SOLUTION\n",
    "with_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a plot of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with_predictions.scatter(\"Spread\", make_array(\"Outcome\", \"Predicted outcome\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 8\n",
    "Is it true that the average outcome for games with each spread is around that spread?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION:** Yes.  The slope and intercept are pretty close to 1 and 0, respectively.  Since the data look roughly linearly related, that means that the average outcome for games with spread around $X$ was roughly $X$, for any number $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 9\n",
    "Do you think the casino predicted game outcomes *accurately*?  What number would you use to quantify that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION:** It wasn't that accurate, though that depends on your standards!  The correlation is an okay way to measure this; 0.49 is okay, but not great.  (Even better would be to compute the mean squared error for the line `predicted outcome = spread`, rather than for the best-fit line we found, `predicted outcome ~= .95*spread - .22`.)  We can also just see visually that the relationship between spread and outcome is very noisy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "## Finding the Least Squares Regression Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you'll work with a small, abstract dataset of 5 x/y pairs.  You'll see 3 ways to find the least-squares regression line.\n",
    "\n",
    "Run the next cell to generate the dataset `d` and see a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = Table().with_columns(\n",
    "    'x', make_array(0,  1,  2,  3,  4),\n",
    "    'y', make_array(1, .5, -1,  2, -3))\n",
    "d.scatter('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "When you run it, the next cell generates sliders that control the slope and intercept of a potential line.  When you adjust a slider, the line will move.\n",
    "\n",
    "#### Question 1\n",
    "By moving the line around, make your best guess at the least-squares regression line.  (It's okay if your line isn't exactly right, as long as it's reasonable.)\n",
    "\n",
    "**Note:** Python will probably take about a second to redraw the plot each time you adjust the slider.  We suggest clicking the place on the slider you want to try and waiting for the plot to be drawn; dragging the slider handle around will cause a long lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_line(slope, intercept):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    \n",
    "    endpoints = make_array(-2, 7)\n",
    "    p = plt.plot(endpoints, slope*endpoints + intercept, color='orange', label='Proposed line')\n",
    "    \n",
    "    plt.scatter(d.column('x'), d.column('y'), color='blue', label='Points')\n",
    "    \n",
    "    plt.xlim(-4, 8)\n",
    "    plt.ylim(-6, 6)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.8, .8))\n",
    "\n",
    "interact(plot_line, slope=widgets.FloatSlider(min=-4, max=4, step=.1), intercept=widgets.FloatSlider(min=-4, max=4, step=.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "You can probably find a reasonable-looking line by just eyeballing it.  But remember: the least-squares regression line minimizes the mean of the squared errors made by the line for each point.  Your eye might not be able to judge squared errors very well.\n",
    "\n",
    "#### A note on mean and total squared error\n",
    "Before we move on, a note is in order.\n",
    "\n",
    "It is common to think of the least-squares line as the line with the least *mean* squared error (or the square root of the mean squared error), as the textbook does.\n",
    "\n",
    "But it turns out that it doesn't matter whether you minimize the mean squared error or the *total* squared error.  You'll get the same best line in either case.\n",
    "\n",
    "That's because the total squared error is just the mean squared error multipled by the number of points (`d.num_rows`).  So if one line gets a better total squared error than another line, then it also gets a better mean squared error.  In particular, the line with the smallest total squared error is also better than every other line in terms of mean squared error.  That makes it the least squares line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Question 2\n",
    "The next cell produces a more useful plot.  Use it to find a line that's closer to the least-squares regression line, keeping the above note in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_line_and_errors(slope, intercept):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    points = make_array(-2, 7)\n",
    "    p = plt.plot(points, slope*points + intercept, color='orange', label='Proposed line')\n",
    "    ax = p[0].axes\n",
    "    \n",
    "    predicted_ys = slope*d.column('x') + intercept\n",
    "    diffs = predicted_ys - d.column('y')\n",
    "    for i in np.arange(d.num_rows):\n",
    "        x = d.column('x').item(i)\n",
    "        y = d.column('y').item(i)\n",
    "        diff = diffs.item(i)\n",
    "        \n",
    "        if diff > 0:\n",
    "            bottom_left_x = x\n",
    "            bottom_left_y = y\n",
    "        else:\n",
    "            bottom_left_x = x + diff\n",
    "            bottom_left_y = y + diff\n",
    "        \n",
    "        ax.add_patch(patches.Rectangle(make_array(bottom_left_x, bottom_left_y), abs(diff), abs(diff), color='red', alpha=.3, label=('Squared error' if i == 0 else None)))\n",
    "        plt.plot(make_array(x, x), make_array(y, y + diff), color='red', alpha=.6, label=('Error' if i == 0 else None))\n",
    "    \n",
    "    plt.scatter(d.column('x'), d.column('y'), color='blue', label='Points')\n",
    "    \n",
    "    plt.xlim(-4, 8)\n",
    "    plt.ylim(-6, 6)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.8, .8))\n",
    "\n",
    "interact(plot_line_and_errors, slope=widgets.FloatSlider(min=-4, max=4, step=.1), intercept=widgets.FloatSlider(min=-4, max=4, step=.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 3\n",
    "Describe the visual criterion you used to find a line in question 2.  (For example, a possible (but incorrect) answer is, \"I tried to make the red line for the bottom-right point as small as possible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION:** We tried to find a line that made the sum of the areas of the squares as small as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 4\n",
    "Does the point at (3, 2) have more or less influence than any other point on the location of the line?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION:** That point has more influence on the line than other points.  Because we used squared error, the error for that point grows very quickly as the line moves away from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's have Python find this line for us.  When we use `minimize`, Python goes through a process similar to the one you might have used in question 2.\n",
    "\n",
    "But Python can't look at a plot that displays errors!  Instead, we tell it how to find the total squared error for a line with a given slope and intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 5\n",
    "Define a function called `total_squared_error`.  It should take two numbers as arguments:\n",
    "\n",
    "1. the slope of some potential line\n",
    "2. the intercept of some potential line\n",
    "\n",
    "It should return the total squared error when we use that line to make predictions for the dataset `d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def total_squared_error(slope, intercept):\n",
    "    # Hint: The staff answer computed an array called predictions\n",
    "    # and an array called errors first.\n",
    "    predictions = slope*d.column('x') + intercept #SOLUTION\n",
    "    errors = predictions - d.column('y') #SOLUTION\n",
    "    return sum(errors**2) #SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tests.grade('q2_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 6\n",
    "What is the total squared error for the line you found by \"eyeballing\" the errors in the first question?  What about the question after that, where you had a better visual aid?  (It's okay if the error went up!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "for_assignment_type": "solution"
   },
   "outputs": [],
   "source": [
    "# Note: These are just from the staff guesses.  Yours might\n",
    "# have been different.\n",
    "eyeballed_error = total_squared_error(-.8, 1.4)\n",
    "aided_error = total_squared_error(-.6, 1.2)\n",
    "print(\"Eyeballed error:\", eyeballed_error, \"\\nAided error:\", aided_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 7\n",
    "Use `minimize` to find the actual slope and intercept of the least-squares regression line.\n",
    "\n",
    "**Note:** `minimize` will return a single array containing the slope as the first element and intercept as the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "for_assignment_type": "solution"
   },
   "outputs": [],
   "source": [
    "line_parameters = minimize(total_squared_error)\n",
    "slope_from_minimize = line_parameters.item(0)\n",
    "intercept_from_minimize = line_parameters.item(1)\n",
    "print(\"Least-squares regression line: predicted_y = {:f}*x + {:f}\".format(slope_from_minimize, intercept_from_minimize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 8\n",
    "What was the total squared error for that line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_total_squared_error = total_squared_error(slope_from_minimize, intercept_from_minimize) #SOLUTION\n",
    "best_total_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to plot this line and its errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_line_and_errors(slope_from_minimize, intercept_from_minimize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 9\n",
    "Compute the correlation between the `\"x\"` and `\"y\"` columns, then use the formula in [13.2](https://www.inferentialthinking.com/chapters/13/2/regression-line.html) to find the slope and intercept of the least-squares regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "for_assignment_type": "solution"
   },
   "outputs": [],
   "source": [
    "x_mean = np.mean(d.column('x'))\n",
    "y_mean = np.mean(d.column('y'))\n",
    "x_std = np.std(d.column('x'))\n",
    "y_std = np.std(d.column('y'))\n",
    "\n",
    "d_r = np.mean((d.column('x') - x_mean) / x_std * (d.column('y') - y_mean) / y_std)\n",
    "slope_from_r = d_r * y_std / x_std\n",
    "intercept_from_r = y_mean - slope_from_r*x_mean\n",
    "print(\"Regression line computed from the correlation: predicted_y = {:f}*x + {:f}\".format(slope_from_r, intercept_from_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Compare this with your answer to question 7 to verify that they're both correct.  They will be a little bit different, because `minimize` is by default accurate only to within $0.01$.  (If they're not roughly the same, try computing the total squared error for both; the one with the smaller error is more likely correct!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "## Triple Jump Distances vs. Vertical Jump Heights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does skill in one sport imply skill in a related sport?  The answer might be different for different activities.  Let us find out whether it's true for the [triple jump](https://en.wikipedia.org/wiki/Triple_jump) (an horizontal jump similar to a long jump) and the vertical jump.  Since we're learning about linear regression, we will look specifically for a *linear* association between skill in the two sports.\n",
    "\n",
    "The following data was collected by observing 40 collegiate level soccer players.  Each athlete's distance in both jump activities was measured (in centimeters). Run the cell below to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run this cell to load the data\n",
    "jumps = Table.read_table('triple_vertical.csv')\n",
    "jumps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 1\n",
    "Before running a regression, it's important to see what the data look like, because our eyes are good at picking out unusual patterns in data.  Draw a scatter plot with the triple jump distances on the horizontal axis and the vertical jump heights on vertical axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jumps.scatter('triple', 'vertical') #SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "**Question 2** Does the correlation coefficient `r` look closer to 0, .5, or -.5? Explain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION:** It definitely looks closer to .5.  The two variables are positively associated, so it's not -.5.  The data roughly follow a line, so the correlation is probably closer to .5 than to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 3\n",
    "Create a function called `regression_parameters`. It takes as its argument a table with two columns.  The first column is the x-axis, and the second column is the y-axis.  It should compute the correlation between the two columns, then compute the slope and intercept of the regression line that predicts the second column from the first.  It should return an array with three elements: the correlation coefficient of the two columns, the slope of the regression line, and the intercept of the regression line.\n",
    "\n",
    "**Hint:** You did a similar thing in lab, though it was spread out across several questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "for_assignment_type": "solution"
   },
   "outputs": [],
   "source": [
    "def regression_parameters(tbl):\n",
    "    vert_mean = np.mean(jumps.column(1))\n",
    "    vert_sd = np.std(jumps.column(1))\n",
    "    triple_mean = np.mean(jumps.column(0))\n",
    "    triple_sd = np.std(jumps.column(0))\n",
    "    r = np.mean((tbl.column(1) - vert_mean)/vert_sd * (tbl.column(0) - triple_mean)/triple_sd)\n",
    "    slope = r * (vert_sd / triple_sd)\n",
    "    intercept = slope * (-triple_mean) + vert_mean\n",
    "    return make_array(r,slope,intercept)\n",
    "\n",
    "parameters = regression_parameters(jumps)\n",
    "jumps_r = parameters.item(0)\n",
    "jumps_slope = parameters.item(1)\n",
    "jumps_intercept = parameters.item(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 4\n",
    "Let's use `regression_parameters` to predict what certain athletes' vertical jump heights would be given their triple jump distances.\n",
    "\n",
    "The world record for the triple jump distance is 18.29 *meters* by Johnathan Edwards. What's our prediction for what Edwards' vertical jump would be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "triple_record_vert_est = jumps_slope * 1829 + jumps_intercept #SOLUTION\n",
    "print(\"Predicted vertical jump distance: {:f} centimeters\".format(triple_record_vert_est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 5\n",
    "Do you trust this estimate? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION:** No; we have absolutely no information on the triple jump distances in any remote region near 18.29 meters, so it's not smart to make an estimate for it based on this sparse data.  In fact, this is around 7 cm higher than the [current world record](http://www.guinnessworldrecords.com/world-records/highest-standing-jump) according to Guinness.  That's not totally implausible, but it seems unlikely.  (Another reasonable answer is that the correlation is not that high, which means that the prediction is not that accurate even if the regression model is valid for data so far to the right of our sample of jumps.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "## The Bootstrap and The Normal Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will explore a dataset that includes the safety inspection scores for restauraunts in the city of Austin, Texas.  We will be interested in determining the average restaurant score (out of 100) for the city from a random sample of the scores.  We'll compare two methods for computing a confidence interval for that quantity: the bootstrap resampling method, and an approximation based on the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just run this cell.\n",
    "pop_restaurants = Table.read_table('restaurant_inspection_scores.csv').drop(5,6)\n",
    "pop_restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 1\n",
    "Plot a histogram of the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "pop_restaurants.hist('Score') #SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the population mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_mean = np.mean(pop_restaurants.column(3))\n",
    "pop_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often it is impossible to find complete datasets like this.  Imagine we instead had access only to a random sample of 100 restaurants, called `restaurant_sample`.  That table is created below. We are interested in using this sample to estimate the population mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "restaurant_sample = pop_restaurants.sample(100, with_replacement=False)\n",
    "restaurant_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 2\n",
    "Plot the histogram of the **sample** scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write your code here:\n",
    "restaurant_sample.hist('Score') #SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the **sample mean**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_mean = np.mean(restaurant_sample.column(3))\n",
    "sample_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 3\n",
    "Complete the function `bootstrap_scores` below. It should take no arguments. It should simulate drawing 5000 resamples from `restaurant_sample` and computing the mean restaurant score in each resample.  It should return an array of those 5000 resample means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bootstrap_scores():\n",
    "    resampled_means = make_array() #SOLUTION\n",
    "    for i in range(5000):\n",
    "        resampled_mean = np.mean(restaurant_sample.sample().column('Score')) #SOLUTION\n",
    "        resampled_means = np.append(resampled_means, resampled_mean) #SOLUTION\n",
    "    return resampled_means #SOLUTION\n",
    "\n",
    "resampled_means = bootstrap_scores()\n",
    "resampled_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 4\n",
    "Make a histogram of the **resampled means**. What sort of a distribution do they look like they follow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write your code here:\n",
    "Table().with_column('Resampled Means',resampled_means).hist() #SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 5\n",
    "Compute a 95 percent confidence interval for the average restaurant score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lower_bound = percentile(2.5,resampled_means) #SOLUTION\n",
    "upper_bound = percentile(97.5, resampled_means) #SOLUTION\n",
    "print(\"95% confidence interval for the average restaurant score, computed by bootstrapping:\\n(\",lower_bound, \",\", upper_bound, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 6\n",
    "Throughout this section, we've looked at histograms of three distributions: the population, the sample, and the means of resamples taken from the sample. Do the population and sample distributions look similar to each other?  What about the population and the means of resamples? Which, if any, look normally distributed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION:** The sample and population distributions look similar.  The population and resampled means distributions don't look similar.  Only the resampled means are normally distributed.  The Central Limit Theorem predicts that they will be normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last question, you'll need to recall two facts.\n",
    "1. If a group of numbers has a normal distribution, around 95% of them lie within 2 standard deviations of their mean.\n",
    "2. The Central Limit Theorem tells us the quantitative relationship between\n",
    "    * the standard deviation of an array of numbers and\n",
    "    * the standard deviation of an array of means of samples taken from those numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 7\n",
    "Without referencing the array `resampled_means` or performing any new simulations, calculate an interval that covers approximately 95% of the numbers in that array.  **You may access `restaurant_sample`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "for_assignment_type": "solution"
   },
   "outputs": [],
   "source": [
    "sample_mean = np.mean(restaurant_sample.column(3))\n",
    "sample_std = np.std(restaurant_sample.column(3))\n",
    "resample_sizes = restaurant_sample.num_rows\n",
    "std_of_means = sample_std / resample_sizes**0.5\n",
    "lower_bound_normal = sample_mean - 2*std_of_means\n",
    "upper_bound_normal = sample_mean + 2*std_of_means\n",
    "print(\"95% confidence interval for the average restaurant score, computed by a normal approximation:\\n(\",lower_bound_normal, \",\", upper_bound_normal, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confidence interval should look very similar to the one you computed in question 5. If not, try calculating the inner 95 percent using 1.96 standard deviations instead of 2, for a more precise calculation. If they are still very different, there may be an error in your code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
